# ğŸ“Š Data Pipeline for Market Data Integration

This project implements a data pipeline to extract, transform, and load (ETL) data from multiple sources into a unified dataset. The pipeline processes data from two companies, standardizes their formats, and combines them into a single CSV file for further analysis.

## ğŸ“ Project Structure

- **`data_raw/`**: Contains raw data files:
  - ğŸ“„ `dados_empresaA.json`: JSON file with data from Company A.
  - ğŸ“„ `dados_empresaB.csv`: CSV file with data from Company B.
- **`data_processed/`**: Stores processed data:
  - âœ… `dados_combinados.csv`: Combined and standardized dataset.
- **`scripts/`**: Contains Python scripts for the ETL process:
  - ğŸ› ï¸ `fusao_mercado_fev_refatorado.py`: Main script for the ETL pipeline.
  - ğŸ§© `processamento_dados_refatorado.py`: Module with helper functions for data processing.
- **`notebook/`**: ğŸ““ Jupyter notebooks for data exploration and validation.

## ğŸ”„ ETL Process

1. **Extract**:
   - ğŸ“¥ Reads data from `dados_empresaA.json` and `dados_empresaB.csv` using the `Dados.leitura_dados` method.

2. **Transform**:
   - ğŸ”§ Standardizes column names using a mapping dictionary.
   - ğŸ”— Merges data from both sources into a unified dataset.

3. **Load**:
   - ğŸ’¾ Saves the combined dataset to `data_processed/dados_combinados.csv`.

## âœ¨ Key Features

- **ğŸ“ Data Standardization**: Ensures consistent column names across datasets.
- **ğŸ”— Data Integration**: Combines data from multiple sources into a single file.
- **ğŸ“ˆ Scalability**: Modular design allows easy extension for additional data sources.

## ğŸ“¥ How to Download the Project

1. Clone the repository using Git:
```bash
   git clone https://github.com/vitorlinsbinski/pipeline_de_dados_python.git
```

2. Navigate to the project directory:
```bash
    cd pipeline_de_dados_python
```

## ğŸ› ï¸ Setup
To ensure a clean and isolated environment for running the project, follow these steps:

1. Create a virtual environment:
```bash
    python3 -m venv .venv
```

2. Activate the virtual environment:
â€¢ On Linux/MacOS:
```bash
    source .venv/bin/activate
```
â€¢ On Windows:
```bash
    venv\Scripts\activate
```

3. Install dependencies:
```bash
    pip install -r requirements.txt
```

## ğŸš€ Usage

1. ğŸ“‚ Place raw data files in the `data_raw/` directory.
2. â–¶ï¸ Run the main script:
```bash
   python scripts/fusao_mercado_fev_refatorado.py
```